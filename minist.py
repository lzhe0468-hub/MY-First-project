import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import time
import matplotlib.pyplot as plt
def check_environment():
    print("-" * 30)
    print("æ­£åœ¨æ£€æŸ¥ PyTorch ç¯å¢ƒ...")
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    
    # æ£€æŸ¥ GPU è®¾å¤‡
    device = torch.device("cpu")
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… æ£€æµ‹åˆ° NVIDIA æ˜¾å¡: {torch.cuda.get_device_name(0)}")
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… æ£€æµ‹åˆ° Apple Silicon (M1/M2/M3) åŠ é€Ÿ")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU è¿è¡Œ (é€Ÿåº¦è¾ƒæ…¢)")
    
    print("-" * 30)
    return device

# å®šä¹‰ä¸€ä¸ªç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œ (CNN)
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # å·ç§¯å±‚ 1: è¾“å…¥1é€šé“(é»‘ç™½å›¾)ï¼Œè¾“å‡º32é€šé“
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        # å·ç§¯å±‚ 2: è¾“å…¥32é€šé“ï¼Œè¾“å‡º64é€šé“
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10) # 10ä¸ªæ•°å­—åˆ†ç±»
        # æ¿€æ´»ä¸æ± åŒ–
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(2, 2)

    def forward(self, x):
        # ç¬¬ä¸€å±‚: å·ç§¯ -> ReLU -> æ± åŒ–
        x = self.pool(self.relu(self.conv1(x)))
        # ç¬¬äºŒå±‚: å·ç§¯ -> ReLU -> æ± åŒ–
        x = self.pool(self.relu(self.conv2(x)))
        # å±•å¹³
        x = x.view(-1, 64 * 7 * 7)
        # å…¨è¿æ¥
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def main():
    # 1. ç¯å¢ƒæ£€æŸ¥
    device = check_environment()

    # 2. æ•°æ®å‡†å¤‡ (è‡ªåŠ¨ä¸‹è½½ MNIST)
    print("\næ­£åœ¨å‡†å¤‡æ•°æ® (é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½)...")
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,)) # MNIST çš„æ ‡å‡†å‡å€¼å’Œæ–¹å·®
    ])
    
    try:
        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
        print("âœ… æ•°æ®é›†åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ: {e}")
        return

    # 3. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = SimpleCNN().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    # 4. è¯•è¿è¡Œè®­ç»ƒ (åªè·‘ 1 ä¸ª Epoch éªŒè¯ç¯å¢ƒ)
    print(f"\nå¼€å§‹åœ¨ {device} ä¸Šè¿›è¡Œæµ‹è¯•è®­ç»ƒ (1ä¸ª Epoch)...")
    model.train()
    
    start_time = time.time()
    for batch_idx, (data, target) in enumerate(train_loader):
        # æ¬è¿æ•°æ®åˆ° GPU
        data, target = data.to(device), target.to(device)
        
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        output = model(data)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(output, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ›´æ–°å‚æ•°
        optimizer.step()
        
        if batch_idx % 100 == 0:
            print(f'Batch {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f}')
            
        # ä¸ºäº†å¿«é€ŸéªŒè¯ï¼Œæˆ‘ä»¬åªè·‘å‰ 300 ä¸ª Batch å°±åœä¸‹
        if batch_idx > 300:
            print("...")
            break

    end_time = time.time()
    print("-" * 30)
    print(f"âœ… æµ‹è¯•å®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f} ç§’")
    print(f"ğŸ‰ æ­å–œï¼ä½ çš„ PyTorch ç¯å¢ƒé…ç½®æ­£ç¡®ï¼Œå¯ä»¥è¿›è¡Œæ·±åº¦å­¦ä¹ äº†ã€‚")

if __name__ == '__main__':
    main()

